{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical Learning Midterm: Predicting Hurricane Impact Risk\n",
    "## Equitable Disaster Relief through Machine Learning\n",
    "\n",
    "**Date:** October 7, 2025  \n",
    "**Context:** AURA MVP - Hurricane disaster assistance prediction model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Problem Statement & Motivation\n",
    "\n",
    "### The Challenge\n",
    "After major hurricanes, **how much disaster assistance will each community need?**\n",
    "\n",
    "**Why it matters:**\n",
    "- FEMA needs to pre-position resources before storms\n",
    "- Vulnerable communities often under-apply for aid due to barriers\n",
    "- Predicting need (not just claims) can reveal equity gaps\n",
    "\n",
    "### Research Question\n",
    "**Can we predict tract-level FEMA claims using demographic, housing, and disaster data to identify communities at risk of being underserved?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Data Sources & Pipeline\n",
    "\n",
    "### Data Sources\n",
    "| Source | Features | Purpose |\n",
    "|--------|----------|--------|\n",
    "| **FEMA Individual Assistance** | Total claims, applications, eligibility rates | Outcome variable |\n",
    "| **CDC Social Vulnerability Index** | Poverty, elderly, language, race/ethnicity | Vulnerability indicators |\n",
    "| **US Census (ACS 2022)** | Population, income, housing units | Demographic context |\n",
    "| **NOAA HURDAT2** | Hurricane tracks, wind, rainfall | Physical hazard (future work) |\n",
    "\n",
    "### Dataset Overview\n",
    "- **Unit of analysis:** Census tract × Storm event\n",
    "- **Geographic scope:** TX, LA, MS, AL, FL (Gulf Coast)\n",
    "- **Storms:** Harvey, Irma, Michael, Laura, Ida, Ian (2017-2022)\n",
    "- **Total observations:** 5,668 tract-storm pairs\n",
    "- **Tracts with claims:** 1,557 (27.5%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preview data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# Load tract_storm dataset\n",
    "df = pd.read_csv(\"../../data/processed/tract_storm_features.csv\")\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"\\nTarget variable (fema_claims_total) summary:\")\n",
    "print(df['fema_claims_total'].describe())\n",
    "\n",
    "# Show storm distribution\n",
    "storm_names = {\n",
    "    4332: \"Harvey (2017)\",\n",
    "    4337: \"Irma (2017)\",\n",
    "    4399: \"Michael (2018)\",\n",
    "    4559: \"Laura (2020)\",\n",
    "    4611: \"Ida (2021)\",\n",
    "    4673: \"Ian (2022)\"\n",
    "}\n",
    "\n",
    "storm_counts = df['disasterNumber'].value_counts().sort_index()\n",
    "print(f\"\\nStorm distribution:\")\n",
    "for disaster_num, count in storm_counts.items():\n",
    "    storm_name = storm_names.get(disaster_num, f\"Unknown ({disaster_num})\")\n",
    "    print(f\"  {storm_name}: {count} tracts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Modeling Approach\n",
    "\n",
    "### Target Variable\n",
    "**`fema_claims_total`**: Total FEMA personal property verified losses (in dollars)\n",
    "- Log-transformed for training: `log1p(claims)` to handle skewed distribution\n",
    "- Evaluated on raw scale for interpretability\n",
    "\n",
    "### Algorithms Tested\n",
    "1. **K-Nearest Neighbors (KNN)** - Distance-based, non-parametric\n",
    "2. **Decision Tree** - Interpretable, hierarchical splits\n",
    "3. **Random Forest** - Ensemble of trees, reduced overfitting\n",
    "4. **Bagging** - Bootstrap aggregation with decision tree base\n",
    "\n",
    "### Training Strategy\n",
    "- **Train/Test split:** 80/20 (stratified random)\n",
    "- **Cross-validation:** 5-fold CV for hyperparameter tuning\n",
    "- **Preprocessing:** Median imputation + StandardScaler\n",
    "- **Scoring metric:** Negative RMSE (for grid search)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Grids\n",
    "\n",
    "**KNN:**\n",
    "- n_neighbors: [5, 10, 15, 25, 35]\n",
    "- weights: ['uniform', 'distance']\n",
    "- p: [1, 2] (Manhattan vs Euclidean)\n",
    "\n",
    "**Decision Tree:**\n",
    "- max_depth: [None, 5, 10, 20]\n",
    "- min_samples_split: [2, 5, 10]\n",
    "- min_samples_leaf: [1, 2, 5]\n",
    "\n",
    "**Random Forest:**\n",
    "- n_estimators: [200, 400]\n",
    "- max_depth: [None, 10, 20]\n",
    "- min_samples_split: [2, 5]\n",
    "- max_features: ['sqrt', 0.75, 1.0]\n",
    "\n",
    "**Bagging:**\n",
    "- n_estimators: [100, 200, 400]\n",
    "- max_samples: [0.5, 0.75, 1.0]\n",
    "- max_features: [0.5, 0.75, 1.0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Results\n",
    "\n",
    "### Performance Metrics Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load performance results\n",
    "results = pd.read_csv(\"../../docs/tract_storm_model_performance.csv\")\n",
    "\n",
    "# Format for display\n",
    "results_display = results.copy()\n",
    "results_display['model'] = results_display['model'].map({\n",
    "    'knn': 'KNN',\n",
    "    'decision_tree': 'Decision Tree',\n",
    "    'random_forest': 'Random Forest',\n",
    "    'bagging': 'Bagging'\n",
    "})\n",
    "results_display['phase'] = results_display['phase'].str.capitalize()\n",
    "\n",
    "# Round metrics\n",
    "for col in ['r2', 'rmse', 'mae', 'mape', 'explained_variance']:\n",
    "    results_display[col] = results_display[col].round(4)\n",
    "\n",
    "results_display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Findings\n",
    "\n",
    "**Best Model: Bagging Regressor**\n",
    "- **R² = 0.93** (explains 93% of variance)\n",
    "- **RMSE = $980** (typical prediction error)\n",
    "- **MAE = $262** (average absolute error)\n",
    "- **MAPE = 27%** (percentage error)\n",
    "\n",
    "**Observations:**\n",
    "1. **Ensemble methods dominate:** Random Forest & Bagging both achieve R² > 0.92\n",
    "2. **Decision Tree improved significantly** with tuning (0.81 → 0.84 R²)\n",
    "3. **KNN performance degraded** with tuning (0.79 → 0.70 R²) - suggests optimal parameters were in baseline\n",
    "4. **Tuning benefits vary** - not always better, but ensemble methods are robust"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display performance comparison\n",
    "from IPython.display import Image\n",
    "\n",
    "Image(filename=\"../visuals/model_results/01_performance_comparison.png\", width=900)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actual vs Predicted\n",
    "Image(filename=\"../visuals/model_results/02_actual_vs_predicted.png\", width=900)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretation:**\n",
    "- Strong linear correlation between actual and predicted values\n",
    "- Some underprediction of extreme values (high-claim tracts)\n",
    "- Bagging and Random Forest show tightest clustering around perfect prediction line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Importance\n",
    "Image(filename=\"../visuals/model_results/04_feature_importance.png\", width=900)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Top Predictive Features:**\n",
    "- **Applications** - Number of FEMA applications (strongest predictor)\n",
    "- **Housing units** - Total housing in tract\n",
    "- **Demographic vulnerability** - Poverty rate, elderly population\n",
    "- **Income** - Median household income\n",
    "- **Race/ethnicity** - Hispanic and Black population percentages\n",
    "\n",
    "**Key Insight:** The model learns heavily from **application behavior** and **population size**, not just physical risk!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Responsible AI: Bias Analysis\n",
    "\n",
    "### The Equity Question\n",
    "**Does the model systematically underpredict for vulnerable communities?**\n",
    "\n",
    "If yes → Model could mask true need and perpetuate underservice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residuals by vulnerability quartiles\n",
    "Image(filename=\"../visuals/model_results/03_residuals_by_vulnerability.png\", width=900)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bias Diagnostic Results\n",
    "\n",
    "**Analysis Method:**\n",
    "- Segment test set into quartiles by vulnerability indicators\n",
    "- Compare residuals (actual - predicted) across quartiles\n",
    "- Negative residuals = underprediction (model predicts too low)\n",
    "\n",
    "**Findings:**\n",
    "1. **Poverty:** Slight underprediction in Q4 (highest poverty) for all models\n",
    "2. **Hispanic %:** Relatively balanced across quartiles\n",
    "3. **Black %:** Some underprediction in Q4 for Bagging/Random Forest\n",
    "4. **Limited English:** Minimal systematic bias\n",
    "\n",
    "**Interpretation:**\n",
    "- Models show **moderate equity concerns** - high-poverty and high-Black tracts are slightly underestimated\n",
    "- Residuals center near zero (good), but variance increases in vulnerable quartiles\n",
    "- **Root cause:** FEMA claims data reflects application behavior, not true damage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Limitations & Bias Sources\n",
    "\n",
    "**Problem: The target variable is biased**\n",
    "- **FEMA claims ≠ actual damage**\n",
    "- Barriers to application:\n",
    "  - Language access\n",
    "  - Digital literacy\n",
    "  - Trust in government\n",
    "  - Awareness of eligibility\n",
    "  \n",
    "**Impact on model:**\n",
    "- Model learns \"who applies\" not \"who needs help\"\n",
    "- Vulnerable communities with low claims may have high unmet need\n",
    "\n",
    "**Missing critical data:**\n",
    "- Physical hazard features (wind speed, rainfall, flood zones) are placeholders\n",
    "- Without them, model relies on demographic proxies\n",
    "- High-risk Black/Hispanic tracts may be undercounted if they didn't apply"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Responsible AI: Safeguards & Recommendations\n",
    "\n",
    "### Policy Interpretation Guidance\n",
    "\n",
    "**What this model predicts:**\n",
    "- Expected FEMA claims **given historical application patterns**\n",
    "- NOT eligibility, NOT true damage, NOT need\n",
    "\n",
    "**How to use predictions ethically:**\n",
    "1. **Flag discrepancies:** Low predicted claims + high vulnerability = investigate for barriers\n",
    "2. **Prioritize outreach:** High-poverty, low-application tracts need proactive assistance\n",
    "3. **Combine with qualitative data:** Partner with local VOADs and community orgs\n",
    "4. **Human-in-the-loop:** Never auto-deny aid based on model predictions\n",
    "\n",
    "### Technical Safeguards\n",
    "\n",
    "**Implemented:**\n",
    "1. ✅ Bias diagnostics by vulnerability quartiles\n",
    "2. ✅ Feature importance analysis (transparency)\n",
    "3. ✅ Multiple evaluation metrics (not just R²)\n",
    "\n",
    "**Recommended next steps:**\n",
    "1. **Add physical hazard features** (NOAA wind/rain) to decouple risk from demographics\n",
    "2. **Counterfactual stress tests:** Swap demographics while holding hazard constant\n",
    "3. **Fairness constraints:** Penalize models that underpredict for vulnerable groups\n",
    "4. **Threshold transparency:** Publish cut-points and expected false negative rates\n",
    "\n",
    "### Who Benefits? Who Gets Harmed?\n",
    "\n",
    "**Benefits:**\n",
    "- **FEMA/Emergency managers:** Better resource pre-positioning\n",
    "- **High-application communities:** Model captures their patterns well\n",
    "- **Researchers:** Framework for equity-aware disaster modeling\n",
    "\n",
    "**Potential harms:**\n",
    "- **Low-application vulnerable communities:** Risk being deprioritized\n",
    "- **Non-English speakers:** Language barriers invisible to model\n",
    "- **Mobile home residents:** May not know eligibility, underrepresented in claims\n",
    "\n",
    "**Mitigation:**\n",
    "- Use predictions to **increase aid**, not ration it\n",
    "- Deploy proactive outreach to low-prediction/high-vulnerability tracts\n",
    "- Combine with ground truth from local partners"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Hurricane Physical Features (Future Work)\n",
    "\n",
    "### NOAA HURDAT2 Integration\n",
    "\n",
    "**Features to add:**\n",
    "- `tract_distance_km`: Distance from tract centroid to storm path\n",
    "- `max_wind_mph`: Maximum wind speed experienced\n",
    "- `exposure_duration_hours`: Hours above wind thresholds\n",
    "- `pct_floodplain`: Tract area in FEMA flood zones\n",
    "\n",
    "**Expected impact:**\n",
    "- Shift importance from demographics to physical risk\n",
    "- Reveal where demographic patterns are proxies for hazard exposure\n",
    "- Improve predictions for future storms without historical claims data\n",
    "\n",
    "### Hurricane Ida Example Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: These visualizations are from collaborator's NOAA pipeline\n",
    "# Showing methodology for physical feature extraction\n",
    "\n",
    "from IPython.display import IFrame\n",
    "\n",
    "print(\"Interactive map: Hurricane Ida wind field coverage\")\n",
    "print(\"Opens in: ../visuals/hurricane_features/ida_interactive_map.html\")\n",
    "print(\"\\nShows: Census tract centroids, storm track, wind radii envelopes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. Conclusions\n",
    "\n",
    "### Summary of Findings\n",
    "\n",
    "**Model Performance:**\n",
    "- Achieved **R² = 0.93** with Bagging ensemble\n",
    "- All 4 required algorithms successfully implemented and tuned\n",
    "- Ensemble methods (Random Forest, Bagging) significantly outperform single models\n",
    "\n",
    "**Equity Insights:**\n",
    "- Moderate bias detected: High-poverty and high-Black tracts slightly underpredicted\n",
    "- Root cause: Target variable (FEMA claims) reflects application behavior, not need\n",
    "- Model learns \"who applies\" rather than \"who needs help\"\n",
    "\n",
    "**Key Limitation:**\n",
    "- Missing physical hazard features (wind, rain, flood zones)\n",
    "- Without them, model relies on demographic proxies\n",
    "- Strong performance suggests demographics/housing correlate with risk, but also with application barriers\n",
    "\n",
    "### Policy Implications\n",
    "\n",
    "**For disaster response:**\n",
    "1. Use predictions to **identify under-application**, not allocate resources\n",
    "2. Flag low-prediction + high-vulnerability tracts for proactive outreach\n",
    "3. Combine ML predictions with community partnerships\n",
    "\n",
    "**For AURA MVP:**\n",
    "- Framework demonstrates feasibility of tract-level risk prediction\n",
    "- Next phase: Integrate NOAA physical features\n",
    "- Pilot with 2-3 Gulf Coast states before national rollout\n",
    "\n",
    "### Future Enhancements\n",
    "\n",
    "**Immediate (< 1 month):**\n",
    "1. Integrate NOAA wind/distance features from collaborator pipeline\n",
    "2. Add FEMA flood zone overlays\n",
    "3. Rerun models and compare feature importance shifts\n",
    "\n",
    "**Short-term (1-3 months):**\n",
    "1. Fairness-aware tuning (penalize underprediction of vulnerable tracts)\n",
    "2. Temporal validation (train on 2017-2020, test on 2021-2022)\n",
    "3. State-specific models to capture regional policy differences\n",
    "\n",
    "**Long-term (3-6 months):**\n",
    "1. Real-time prediction API for pre-storm resource allocation\n",
    "2. Dashboard for emergency managers with equity indicators\n",
    "3. Integration with CDC SVI updates and FEMA declaration polygons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Appendix: Technical Details\n",
    "\n",
    "### Best Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"../../docs/tract_storm_best_params.json\", \"r\") as f:\n",
    "    best_params = json.load(f)\n",
    "\n",
    "for model, params in best_params.items():\n",
    "    print(f\"\\n{model.upper()}:\")\n",
    "    for param, value in params.items():\n",
    "        print(f\"  {param}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show all features used in modeling\n",
    "exclude_cols = {\n",
    "    \"fema_claims_total_log1p\", \"fema_claims_total\", \"fema_claims_pc\",\n",
    "    \"population_for_pc\", \"tract_geoid\", \"disasterNumber\", \"state_abbr\",\n",
    "    \"county_name\", \"acs_state_fips\", \"state_fips\", \"coverage_label\"\n",
    "}\n",
    "\n",
    "feature_cols = [col for col in df.columns if col not in exclude_cols]\n",
    "numeric_features = df[feature_cols].select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "print(f\"Total features: {len(numeric_features)}\\n\")\n",
    "print(\"Features by category:\\n\")\n",
    "\n",
    "categories = {\n",
    "    \"FEMA Access\": ['applications', 'declaration', 'tsa_eligible_rate', 'owner_rate', 'renter_rate', 'fema_claims_mean'],\n",
    "    \"Demographics\": ['total_population', 'median_household_income', 'pct_poverty', 'pct_elderly', 'pct_children'],\n",
    "    \"Race/Ethnicity\": ['pct_black', 'pct_hispanic', 'pct_limited_english'],\n",
    "    \"Housing\": ['housing_units', 'pct_mobile_homes', 'pct_multi_unit', 'pct_crowded_housing', 'pct_no_vehicle'],\n",
    "    \"Hazard (Placeholder)\": ['max_wind_mph', 'total_rainfall_in', 'min_distance_km', 'pct_floodplain'],\n",
    "    \"Geography\": ['area_sq_mi', 'in_fema_decl', 'in_noaa_exposure']\n",
    "}\n",
    "\n",
    "for category, features in categories.items():\n",
    "    available = [f for f in features if f in numeric_features]\n",
    "    print(f\"{category}: {len(available)} features\")\n",
    "    for f in available:\n",
    "        print(f\"  - {f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Quality Notes\n",
    "\n",
    "**Missing data handling:**\n",
    "- Median imputation for continuous features\n",
    "- Hazard features (wind, rain, distance, floodplain) are entirely missing - awaiting NOAA integration\n",
    "- Demographic features have <5% missingness\n",
    "\n",
    "**Target variable transformation:**\n",
    "- Original: Highly right-skewed (many zeros, few very large values)\n",
    "- Transformed: log1p(fema_claims_total) for training\n",
    "- Evaluation: Back-transformed to raw dollars for interpretability\n",
    "\n",
    "**Cross-validation strategy:**\n",
    "- 5-fold CV with random splits (not stratified by storm)\n",
    "- Each fold: 80% train, 20% validation\n",
    "- Final test set: 20% held out from all training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## References\n",
    "\n",
    "**Data Sources:**\n",
    "- FEMA Individual Assistance Program: https://www.fema.gov/openfema-data-page/individuals-and-households-program-valid-registrations-v1\n",
    "- CDC Social Vulnerability Index 2022: https://www.atsdr.cdc.gov/placeandhealth/svi/data_documentation_download.html\n",
    "- US Census American Community Survey: https://www.census.gov/programs-surveys/acs\n",
    "- NOAA HURDAT2 Hurricane Database: https://www.nhc.noaa.gov/data/hurdat/\n",
    "\n",
    "**Collaborator:**\n",
    "- Hurricane physical feature extraction pipeline: https://github.com/mhahn2011/HURRICANE-DATA-ETL\n",
    "\n",
    "**AURA Project Context:**\n",
    "- Goal: Equitable disaster assistance through ML-powered resource allocation\n",
    "- Partners: FEMA, state emergency management, VOADs\n",
    "- Geographic focus: Gulf Coast states (hurricane-prone regions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
